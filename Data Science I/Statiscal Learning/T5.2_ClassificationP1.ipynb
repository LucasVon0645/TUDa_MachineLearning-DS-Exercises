{"cells":[{"cell_type":"markdown","metadata":{"id":"U2GDvoEpAzjr"},"source":["# Data Science 1 - Tutorial 5.2 - Classification Part 1"]},{"cell_type":"markdown","metadata":{"id":"y49sEXwuAzj_"},"source":["## Classification evaluation metrics"]},{"cell_type":"markdown","metadata":{"id":"FRROGFQIAzkA"},"source":["Table 1 shows the dataset showing the characteristics of a tumor mass with their respective labels (Benign or Malignant). A colleague proposed a cancer (malignant tumor) detector that outputs the class Malignant if the Radius>5 and Area>5, and the class Benign otherwise. Calculate the accuracy, precision, recall, specificity, F1 score, and balanced accuracy of this detector.\n","\n","\n","<center><b>Table 1: Tumor data and labels</b></center>\n","\n","| Radius | Perimeter | Area | Category |\n","| --- | --- | --- | --- |\n","| 5 | 1 | 1 | Benign |\n","| 5 | 4 | 5 | Benign |\n","| 3 | 1 | 1 | Benign |\n","| 6 | 8 | 1 | Benign |\n","| 4 | 1 | 3 | Benign |\n","| 8 | 10 | 8 | Malignant |\n","| 1 | 1 | 1 | Benign |\n","| 2 | 2 | 1 | Benign |\n","| 2 | 1 | 1 | Benign |\n","| 4 | 1 | 1 | Benign |\n","| 1 | 1 | 1 | Benign |\n","| 2 | 1 | 1 | Benign |\n","| 5 | 3 | 3 | Malignant |\n","| 1 | 1 | 1 | Benign |\n","| 8 | 5 | 10 | Malignant |\n","| 7 | 6 | 4 | Malignant |\n","| 4 | 1 | 1 | Benign |\n","| 4 | 1 | 1 | Benign |\n","| 10 | 7 | 6 | Malignant |\n","| 6 | 1 | 1 | Benign |\n","| 7 | 2 | 10 | Malignant |\n","| 10 | 5 | 3 | Malignant |\n","| 3 | 1 | 1 | Benign |\n"]},{"cell_type":"markdown","metadata":{"id":"CR0BORmgAzkD"},"source":["**A**: ..."]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n","\n","\n","data = {\n","    \"Radius\": [5, 5, 3, 6, 4, 8, 1, 2, 2, 4, 1, 2, 5, 1, 8, 7, 4, 4, 10, 6, 7, 10, 3],\n","    \"Perimeter\": [1, 4, 1, 8, 1, 10, 1, 2, 1, 1, 1, 1, 3, 1, 5, 6, 1, 1, 7, 1, 2, 5, 1],\n","    \"Area\": [1, 5, 1, 1, 3, 8, 1, 1, 1, 1, 1, 1, 3, 1, 10, 4, 1, 1, 6, 1, 10, 3, 1],\n","    \"Category\": [\"Benign\", \"Benign\", \"Benign\", \"Benign\", \"Benign\", \"Malignant\", \"Benign\", \"Benign\", \"Benign\", \"Benign\", \"Benign\", \"Benign\", \"Malignant\", \"Benign\", \"Malignant\", \"Malignant\", \"Benign\", \"Benign\", \"Malignant\", \"Benign\", \"Malignant\", \"Malignant\", \"Benign\"]\n","}\n","\n","cancer_df = pd.DataFrame(data)\n"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"data":{"text/plain":["Category\n","Benign       16\n","Malignant     7\n","Name: count, dtype: int64"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["cancer_df.value_counts(\"Category\")"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy:  0.8695652173913043\n","Precision:  1.0\n","Recall:  0.5714285714285714\n","F1:  0.7272727272727273\n","Confusion Matrix: \n","[[16  0]\n"," [ 3  4]]\n"]}],"source":["\n","classes = {\"Benign\": 0, \"Malignant\": 1}\n","\n","cancer_df[\"Category\"] = cancer_df[\"Category\"].apply(lambda c: classes[c])\n","\n","pred_s = (cancer_df[\"Area\"] > 5) & (cancer_df[\"Radius\"] > 5)\n","pred_s = pred_s.astype(\"int\")\n","\n","cancer_df[\"Prediction\"] = pred_s\n","\n","print(\"Accuracy: \", accuracy_score(cancer_df[\"Category\"], pred_s))\n","print(\"Precision: \", precision_score(cancer_df[\"Category\"], pred_s))\n","print(\"Recall: \", recall_score(cancer_df[\"Category\"], pred_s))\n","print(\"F1: \", f1_score(cancer_df[\"Category\"], pred_s))\n","\n","print(\"Confusion Matrix: \")\n","print(confusion_matrix(cancer_df[\"Category\"], pred_s))"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Radius</th>\n","      <th>Perimeter</th>\n","      <th>Area</th>\n","      <th>Category</th>\n","      <th>Prediction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>8</td>\n","      <td>10</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>8</td>\n","      <td>5</td>\n","      <td>10</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>7</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>10</td>\n","      <td>7</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>7</td>\n","      <td>2</td>\n","      <td>10</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>10</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    Radius  Perimeter  Area  Category  Prediction\n","0        5          1     1         0           0\n","1        5          4     5         0           0\n","2        3          1     1         0           0\n","3        6          8     1         0           0\n","4        4          1     3         0           0\n","5        8         10     8         1           1\n","6        1          1     1         0           0\n","7        2          2     1         0           0\n","8        2          1     1         0           0\n","9        4          1     1         0           0\n","10       1          1     1         0           0\n","11       2          1     1         0           0\n","12       5          3     3         1           0\n","13       1          1     1         0           0\n","14       8          5    10         1           1\n","15       7          6     4         1           0\n","16       4          1     1         0           0\n","17       4          1     1         0           0\n","18      10          7     6         1           1\n","19       6          1     1         0           0\n","20       7          2    10         1           1\n","21      10          5     3         1           0\n","22       3          1     1         0           0"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["cancer_df"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy:  0.8695652173913043\n","Precision:  1.0\n","Recall:  0.5714285714285714\n","F1:  0.7272727272727273\n"]}],"source":["pivot = pd.pivot_table(cancer_df, index=\"Category\", columns=\"Prediction\", aggfunc=\"count\", values=\"Radius\", fill_value=0, margins=True)\n","\n","true_positive = pivot.iloc[1,1]\n","true_negative = pivot.iloc[0,0]\n","false_negative = pivot.iloc[1,0]\n","false_positive = pivot.iloc[0,1]\n","\n","accuracy = (true_positive + true_negative)/len(cancer_df)\n","\n","precision = (true_positive)/(false_positive + true_positive)\n","\n","recall = (true_positive)/(true_positive + false_negative)\n","\n","f1 = 2/(1/precision + 1/recall)\n","\n","print(\"Accuracy: \", accuracy)\n","print(\"Precision: \", precision)\n","print(\"Recall: \", recall)\n","print(\"F1: \", f1)"]},{"cell_type":"markdown","metadata":{"id":"TJ31C0pjAzkE"},"source":["## Bayes' theorem"]},{"cell_type":"markdown","metadata":{"id":"3-xqHL_dAzkF"},"source":["Printer failures are associated with three types of problems: hardware, software, and other (such as human error), with probabilities 0.1, 0.6, and 0.3, respectively. The probability of a printer failure given a hardware problem is 0.9, given a software problem is 0.2, and given any other problem is 0.5. If a customer enters the manufacturerâ€™s Web site to diagnose a printer failure, what is the most likely cause of the problem?"]},{"cell_type":"markdown","metadata":{"id":"u18JdQrWAzkH"},"source":["**A**: The posterior P(Software | Failure) = 0.6 is the highest. Therefore, \"software\" is the most likely class for the failure type. However, if the first probabilities given in the problem are the actually the prior probabilities over the classes of failure, then we need to compute the posterior probabilities and choose the maximum one: \n","\n","- P(S|F) = P(F|S)P(S)/P(F)\n","- P(H|F) = P(F|H)P(H)/P(F)\n","- P(O|F) = P(F|O)P(O)/P(F)\n","\n","with P(F) = P(F|S)P(S) + P(F|H)P(H) + P(F|O)P(O)"]},{"cell_type":"markdown","metadata":{"id":"qiUEwzzKAzkK"},"source":["## Decision Tree"]},{"cell_type":"markdown","metadata":{"id":"8NDCJtBUAzkL"},"source":["1. Is the (ID3) decision tree algorithm that we saw in the lecture a greedy algorithm? Explain.\n","2. Still using the dataset in Table 1, discretize all the numerical features into $\\leq5$ and $>5$ and derive the decision tree using the ID3 algorithm."]},{"cell_type":"markdown","metadata":{"id":"Onk5891EAzkN"},"source":["**A**: ..."]},{"cell_type":"markdown","metadata":{"id":"KW5ZspJlAzkO"},"source":["## Support Vector Machine"]},{"cell_type":"markdown","metadata":{"id":"4vDSXbf8AzkO"},"source":["In the lecture we saw the following standard quadratic optimization\n","problem:\n","$$\n","\\begin{align}\n","\\underset{\\boldsymbol{w}}{\\text{minimize}}\\frac{1}{2}\\left\\Vert \\boldsymbol{w}\\right\\Vert ^{2}\\\\\n","\\text{subject to }\\forall j,\\;y^{(j)}\\left(\\boldsymbol{w}^{\\intercal}\\boldsymbol{x}^{(j)}+w_{0}\\right) & \\geq1.\n","\\end{align}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"9YZA_xwAAzkP"},"source":["In finding the optimal hyperplane, we can convert the optimization\n","problem to an unconstrained problem using Lagrange multipliers $\\alpha^{(j)}$:\n","\n","$$\n","\\begin{align}\n","L_{p} & =\\frac{1}{2}\\left\\Vert \\boldsymbol{w}\\right\\Vert ^{2}-\\sum_{j}\\alpha^{(j)}\\left\\{ y^{(j)}\\left(\\boldsymbol{w}^{\\intercal}\\boldsymbol{x}^{(j)}+w_{0}\\right)-1\\right\\} \\\\\n"," & =\\frac{1}{2}\\left(\\boldsymbol{w}^{\\intercal}\\boldsymbol{w}\\right)-\\boldsymbol{w}^{\\intercal}\\sum_{j}\\alpha^{(j)}y^{(j)}\\boldsymbol{x}^{(j)}-w_{0}\\sum_{j}\\alpha^{(j)}y^{(j)}+\\sum_{j}\\alpha^{(j)}\n","\\end{align}\n","$$\n","\n","for $j=1,\\ldots,n$ samples. This should be minimized w.r.t. $\\boldsymbol{w},w_{0}$\n","and maximized w.r.t. $\\alpha^{(j)}\\geq0$."]},{"cell_type":"markdown","metadata":{"id":"5bjb6ALPAzkP"},"source":["1. Find the partial derivatives of $ L_{p} $ with respect to $ \\boldsymbol{w} $ and $ w_{0} $ and set them to zero.\n","\n","2. Since the main minimization problem and the linear constraints are convex, we can solve the dual problem. Plug the the equations you get into $L_{p}$, which now we call the dual $L_{d}$, such that you don't see the terms $\\boldsymbol{w}$ or $w_{0}$ anymore.\n","\n","3. Research: What is the dual problem, what are the constraints? What values of $\\alpha$'s do the support vectors take? What are the values of the $\\alpha$'s for the rest of the samples?\n","\n","4. Given two samples $ \\boldsymbol{x}^{(1)}=\\left(2,2\\right),\\boldsymbol{x}^{(2)}=\\left(5,6\\right)$ with labels $y$ equal to +1 and -1 respectively. By using the information that the lagrange multipliers can be obtained from: $$ \\alpha^{(1)}=\\alpha^{(2)}=\\frac{2}{\\left(x_{1}^{(1)}-x_{1}^{(2)}\\right)^{2}+\\left(x_{2}^{(1)}-x_{2}^{\\left(2\\right)}\\right)^{2}},$$ find the optimal separating plane.\n","\n","5. In the lecture, we saw the samples whose two classes are linearly separable. In the case where there is no hyperplane to separate the classes, look for one that gives the least error. This is called the soft margin hyperplane and we define slack variables $\\xi^{(j)}\\geq0 $ for $ j=1,2,\\ldots,n$ samples. Research: Write down the new optimization problem. What are the values of $ \\xi^{(j)} $ that correspond to the data points within the margin, and the $ \\xi^{(j)} $ for the misclassified data points?"]},{"cell_type":"markdown","metadata":{"id":"mj-p9x92AzkQ"},"source":["**A**: ..."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":true,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"165px"},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":0}
